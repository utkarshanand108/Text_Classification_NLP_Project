{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration\n"
      ],
      "metadata": {
        "id": "UT3PNtnPRVM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "df = pd.read_excel('text_class.xlsx')  # file must be uploaded first\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Print total number of rows and unique labels\n",
        "print(\"\\nTotal number of rows:\", len(df))\n",
        "print(\"Unique labels and their counts:\")\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "id": "0-YELyZVHilZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fca40b-b2a9-4666-eec8-93110c1f9a91"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "                                                text     label\n",
            "0                 I loved the product, it's amazing!  positive\n",
            "1    Terrible service, I will never shop here again.  negative\n",
            "2    The quality is good, but the delivery was late.   neutral\n",
            "3  Absolutely wonderful experience, highly recomm...  positive\n",
            "4  Product was damaged when it arrived, very disa...  negative\n",
            "\n",
            "Total number of rows: 8\n",
            "Unique labels and their counts:\n",
            "label\n",
            "positive    3\n",
            "negative    3\n",
            "neutral     2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, I loaded the dataset into a pandas DataFrame.\n",
        "I displayed the first 5 rows to understand the structure of the data and printed the total number of rows along with the counts of unique labels.\n",
        "This helps in knowing the dataset size and the class distribution before preprocessing."
      ],
      "metadata": {
        "id": "9aQ99sf6YGGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Text Data\n"
      ],
      "metadata": {
        "id": "J3O1XkMmRwBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Define stopwords (English)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean text\n",
        "def preprocess_text(text):\n",
        "    # 1. Lowercase\n",
        "    text = text.lower()\n",
        "    # 2. Remove punctuation & special characters (keep only letters and spaces)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # 3. Tokenize (split into words)\n",
        "    words = text.split()\n",
        "    # 4. Remove stopwords\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    # 5. Join back to sentence\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Apply preprocessing to the text column\n",
        "df['clean_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Show first 5 cleaned rows\n",
        "print(\"âœ… First 5 rows after preprocessing:\")\n",
        "print(df[['text', 'clean_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awocyKhRWm_3",
        "outputId": "db03600b-7c64-49d4-844b-27487c371b8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… First 5 rows after preprocessing:\n",
            "                                                text  \\\n",
            "0                 I loved the product, it's amazing!   \n",
            "1    Terrible service, I will never shop here again.   \n",
            "2    The quality is good, but the delivery was late.   \n",
            "3  Absolutely wonderful experience, highly recomm...   \n",
            "4  Product was damaged when it arrived, very disa...   \n",
            "\n",
            "                                         clean_text  \n",
            "0                             loved product amazing  \n",
            "1                       terrible service never shop  \n",
            "2                        quality good delivery late  \n",
            "3  absolutely wonderful experience highly recommend  \n",
            "4              product damaged arrived disappointed  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Preprocess and vectorize text\n",
        "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
        "X = vectorizer.fit_transform(df['clean_text'])\n",
        "\n",
        "# Keep labels separately\n",
        "y = df['label']\n",
        "\n",
        "# Print processed sample\n",
        "print(\"âœ… TF-IDF processed matrix shape:\", X.shape)\n",
        "print(\"\\nðŸ§¾ Feature names (first 10):\", vectorizer.get_feature_names_out()[:10])"
      ],
      "metadata": {
        "id": "BNJRH3ubRxtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59e77a2-b154-47ab-a0ce-a7b69530c89f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… TF-IDF processed matrix shape: (8, 28)\n",
            "\n",
            "ðŸ§¾ Feature names (first 10): ['absolutely' 'amazing' 'arrived' 'customer' 'damaged' 'delivery'\n",
            " 'disappointed' 'experience' 'good' 'helpful']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I applied text preprocessing to clean the raw text.\n",
        "I converted all text to lowercase, removed punctuation and special characters, tokenized the sentences, and removed stopwords.\n",
        "This ensures that only meaningful words remain.\n",
        "I also displayed the first 5 cleaned rows for verification.\n",
        "Finally, I used TF-IDF Vectorizer to transform the cleaned text into numerical features."
      ],
      "metadata": {
        "id": "rXEg62qIYQg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a Classifier"
      ],
      "metadata": {
        "id": "cDxp0o7sR9N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"ðŸŽ¯ Accuracy of the model:\", accuracy)"
      ],
      "metadata": {
        "id": "PXkDbep-R-XB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc405db-0d6d-4203-fbd9-2fad56a28810"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Accuracy of the model: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I split the dataset into training (80%) and testing (20%) sets.\n",
        "Then I trained a Logistic Regression classifier on the training data.\n",
        "After predicting on the test set, I calculated the accuracy.\n",
        "The accuracy is very low because the dataset is very small (only 8 rows total), which makes the test set unreliable.\n",
        "This shows the importance of having larger datasets in machine learning."
      ],
      "metadata": {
        "id": "8NkF4bK6YRc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model"
      ],
      "metadata": {
        "id": "hg4FBwZkSBDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nðŸ§¾ Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "LuJLd6ygSELI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262554e9-00b0-46f9-9f16-d7f8a893e273"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§¾ Confusion Matrix:\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a confusion matrix to evaluate the modelâ€™s predictions.\n",
        "The confusion matrix shows how many predictions were correct and where the model made mistakes.\n",
        "It helps in analyzing performance by comparing true labels with predicted labels for each class."
      ],
      "metadata": {
        "id": "DgbP8l0PYUDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix helps analyze the results by showing the number of correct and incorrect predictions for each class. It allows us to see not only the overall accuracy but also which specific labels were misclassified and where the model is making mistakes."
      ],
      "metadata": {
        "id": "2kCFJoMBYhoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The accuracy score shows the overall performance of the logistic regression model.\n",
        "\n",
        "The confusion matrix helps analyze which classes the model predicted correctly and where it made mistakes. It shows the counts of true vs. predicted labels for each class.\n"
      ],
      "metadata": {
        "id": "jIkCHNeKSK7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By,\n",
        "Utkarsh Anand"
      ],
      "metadata": {
        "id": "9qXTApMNY_1r"
      }
    }
  ]
}